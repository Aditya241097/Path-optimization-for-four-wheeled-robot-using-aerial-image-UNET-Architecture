# -*- coding: utf-8 -*-
"""FORmajor3.6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14woNalyoK1gMvPHDLJa2tlzBO2i9d1-A

# ***ROS node code for simulation for FORmajor2.6***

working for compressed path with letting you choose start and end cordinates
"""

import rclpy
#from rclpy.qos QoSProfile, ReliabilityPolicy, HistoryPolicy #new thing
from rclpy.node import Node
from geometry_msgs.msg import Twist
from nav_msgs.msg import Odometry
from visualization_msgs.msg import Marker, MarkerArray
import numpy as np
import heapq
import math
import cv2
import os

import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import Conv2DTranspose

from sensor_msgs.msg import Image
from cv_bridge import CvBridge

import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning)




class PIDController:
    def __init__(self, kp, ki, kd, dt=0.1, integral_limit=10.0, derivative_limit=10.0):
        self.kp = kp
        self.ki = ki
        self.kd = kd
        self.dt = dt
        self.integral = 0
        self.prev_error = 0
        self.integral_limit = integral_limit
        self.derivative_limit = derivative_limit

    def update(self, error):
        self.integral += error * self.dt
        self.integral = np.clip(self.integral, -self.integral_limit, self.integral_limit)
        derivative = (error - self.prev_error) / self.dt
        derivative = np.clip(derivative, -self.derivative_limit, self.derivative_limit)
        output = self.kp * error + self.ki * self.integral + self.kd * derivative
        self.prev_error = error
        if np.isnan(output) or np.isinf(output):
            output = 0
        return output

class TurtleBotController(Node):
    def __init__(self):
        super().__init__('turtlebot_controller')

        # Parameters
        self.path = generate_path()

        self.current_index = 0
        self.position = np.array([0.0, 0.0], dtype=np.float32)
        self.orientation = 0.0
        self.reached_goal = False
        self.dt = 0.1

        # Initialize PID Controllers
        self.linear_pid = PIDController(kp=1.0, ki=0.02, kd=0.2, dt=self.dt)
        self.angular_pid = PIDController(kp=2.0, ki=0.15, kd=0.2, dt=self.dt)

        # Publishers and Subscribers
        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)
        self.odom_sub = self.create_subscription(Odometry, '/odom', self.odom_callback, 10)

        # Marker publisher
        self.marker_pub = self.create_publisher(MarkerArray, '/waypoints_markers', 10)

        # Timer for control loop and marker publishing
        self.timer = self.create_timer(self.dt, self.control_loop)
        self.marker_timer = self.create_timer(1.0, self.publish_markers)

    def odom_callback(self, msg):
        self.position[0] = msg.pose.pose.position.x
        self.position[1] = msg.pose.pose.position.y
        q = msg.pose.pose.orientation
        _, _, yaw = self.quaternion_to_euler(q.x, q.y, q.z, q.w)
        self.orientation = yaw

    def quaternion_to_euler(self, x, y, z, w):
        t3 = +2.0 * (w * z + x * y)
        t4 = +1.0 - 2.0 * (y * y + z * z)
        return (0.0, 0.0, math.atan2(t3, t4))

    def control_loop(self):
        if self.current_index >= len(self.path) or self.reached_goal:
            self.cmd_vel_pub.publish(Twist())
            self.reached_goal = True
            return

        target = np.array(self.path[self.current_index], dtype=np.float32)
        error_vector = target - self.position
        distance_error = np.linalg.norm(error_vector)

        if distance_error < 0.1:
            self.current_index += 1
            if self.current_index >= len(self.path):
                self.reached_goal = True
                self.cmd_vel_pub.publish(Twist())
            return

        target_angle = np.arctan2(error_vector[1], error_vector[0])
        angular_error = target_angle - self.orientation
        angular_error = (angular_error + np.pi) % (2 * np.pi) - np.pi

        vx = self.linear_pid.update(distance_error)
        omega = self.angular_pid.update(angular_error)

        cmd_msg = Twist()
        cmd_msg.linear.x = np.clip(vx, 0.0, 0.5)
        cmd_msg.angular.z = np.clip(omega, -1.9, 1.9)
        self.cmd_vel_pub.publish(cmd_msg)

    def publish_markers(self):
        marker_array = MarkerArray()

        # Markers for target path
        for i, (x, y) in enumerate(self.path):
            marker = Marker()
            marker.header.frame_id = "odom"
            marker.type = Marker.SPHERE
            marker.action = Marker.ADD
            marker.pose.position.x = float(x)
            marker.pose.position.y = float(y)
            marker.pose.position.z = 0.0
            marker.scale.x = 0.1
            marker.scale.y = 0.1
            marker.scale.z = 0.1
            marker.color.a = 1.0
            marker.color.r = 1.0
            marker.color.g = 0.0
            marker.color.b = 0.0
            marker.id = i
            marker_array.markers.append(marker)

        # Marker for followed path (updated robot position)
        followed_marker = Marker()
        followed_marker.header.frame_id = "odom"
        followed_marker.type = Marker.SPHERE
        followed_marker.action = Marker.ADD
        followed_marker.pose.position.x = float(self.position[0])
        followed_marker.pose.position.y = float(self.position[1])
        followed_marker.pose.position.z = 0.0
        followed_marker.scale.x = 0.15
        followed_marker.scale.y = 0.15
        followed_marker.scale.z = 0.15
        followed_marker.color.a = 1.0
        followed_marker.color.r = 0.0
        followed_marker.color.g = 1.0
        followed_marker.color.b = 0.0
        followed_marker.id = len(self.path)  # Unique ID for this marker
        marker_array.markers.append(followed_marker)

        self.marker_pub.publish(marker_array)


#ML part
def custom_conv2d_transpose(*args, **kwargs):
    kwargs.pop('groups', None)  # Remove the 'groups' argument
    return Conv2DTranspose(*args, **kwargs)

# Function to load a single image and preprocess it
def load_single_image(image_path, shape=128):
    """
    Load and preprocess a single image.

    Parameters:
    image_path (str): Path to the image file.
    shape (int): Shape to resize the image to (default is 128x128).

    Returns:
    numpy array: Preprocessed image ready for model input.
    """
    img = plt.imread(image_path)
    img = cv2.resize(img, (shape, shape))  # Resize to match the model input size
    return np.expand_dims(img, axis=0)  # Add batch dimension

# Function to save the preprocessed mask as an image
def save_preprocessed_mask(mask, save_path):
    """
    Save the preprocessed mask to the specified file path.

    Parameters:
    mask (numpy array): The preprocessed mask image (binary format).
    save_path (str): The file path where the mask image will be saved.
    """
    if mask.max() <= 1:  # If mask values are between 0 and 1
        mask = (mask * 255).astype('uint8')
    else:
        mask = mask.astype('uint8')

    cv2.imwrite(save_path, mask)
    print(f"Mask saved at {save_path}")

# Function to process the mask
def postprocess_mask(mask):
    binary_mask = (mask > 0.5).astype('uint8') * 255
    kernel = np.ones((3, 3), np.uint8)
    dilated_mask = cv2.dilate(binary_mask, kernel, iterations=1)

    def skeletonize(mask):
        _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)
        skeleton = np.zeros_like(binary_mask)
        kernel = np.ones((3, 3), np.uint8)
        while True:
            eroded = cv2.erode(binary_mask, kernel)
            temp = cv2.subtract(binary_mask, eroded)
            skeleton = cv2.bitwise_or(skeleton, temp)
            binary_mask = eroded
            if cv2.countNonZero(binary_mask) == 0:
                break
        return skeleton

    def aggressive_closing(mask, kernel_size=(5, 5)):
        kernel = np.ones(kernel_size, np.uint8)
        return cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

    skeletonized_mask = skeletonize(dilated_mask)
    closed_mask = aggressive_closing(skeletonized_mask, kernel_size=(5, 5))
    smoothed_mask = cv2.GaussianBlur(closed_mask, (5, 5), 0)
    _, final_mask = cv2.threshold(smoothed_mask, 127, 255, cv2.THRESH_BINARY)

    return final_mask

# Function to predict mask for a single image, save it, and plot the result
def predict_and_save_single_image(image_path, model, save_dir='home/thandava/turtlebotsid/src/robot_control/predictResults', shape=128):
    """
    Predict mask for a single image, save it, and plot the result.

    Parameters:
    image_path (str): Path to the input image.
    model (Keras model): Trained model for prediction.
    save_dir (str): Directory to save the preprocessed mask.
    shape (int): Shape to resize the image to for model input (default is 128x128).

    Returns:
    str: Path to the saved preprocessed mask image.
    """
    os.makedirs(save_dir, exist_ok=True)

    # Load and preprocess the image
    img = load_single_image(image_path, shape=shape)

    # Predict the mask
    prediction = model.predict(img)[0, :, :, 0]  # Extract the single mask from batch

    # Postprocess the mask
    preprocessed_mask = postprocess_mask(prediction)

    # Save the preprocessed mask
    save_path = os.path.join(save_dir, os.path.basename(image_path).replace('.jpg', '_mask.jpg'))
    save_preprocessed_mask(preprocessed_mask, save_path)

    # Plot the input image and its mask
    plt.figure(figsize=(12, 6))

    # Original Image
    plt.subplot(1, 2, 1)
    plt.imshow(plt.imread(image_path))
    plt.title('Original Image')

    # Preprocessed Mask
    plt.subplot(1, 2, 2)
    plt.imshow(preprocessed_mask, cmap='gray')
    plt.title('Preprocessed Mask')

    plt.show()

    return save_path



# A* algorithm with diagonal movement and Euclidean distance
def astar(grid, start, goal):
    def heuristic(a, b):
        return np.sqrt((a[0] - b[0])**2 + (a[1] - b[1])**2)  # Euclidean distance

    # Priority queue to hold nodes to explore
    open_set = []
    heapq.heappush(open_set, (0, start))

    came_from = {}
    g_score = {start: 0}
    f_score = {start: heuristic(start, goal)}

    while open_set:
        _, current = heapq.heappop(open_set)

        if current == goal:
            return reconstruct_path(came_from, current)

        for neighbor in get_neighbors(grid, current):
            tentative_g_score = g_score[current] + heuristic(current, neighbor)

            if neighbor not in g_score or tentative_g_score < g_score[neighbor]:
                came_from[neighbor] = current
                g_score[neighbor] = tentative_g_score
                f_score[neighbor] = g_score[neighbor] + heuristic(neighbor, goal)
                heapq.heappush(open_set, (f_score[neighbor], neighbor))

    return None  # No path found

# Reconstruct the shortest path
def reconstruct_path(came_from, current):
    path = [current]
    while current in came_from:
        current = came_from[current]
        path.append(current)
    return path[::-1]

# Function to get valid neighbors of a cell, including diagonal movement
def get_neighbors(grid, node):
    neighbors = []
    x, y = node
    for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1), (-1, -1), (-1, 1), (1, -1), (1, 1)]:  # Diagonal moves included
        nx, ny = x + dx, y + dy
        if 0 <= nx < grid.shape[0] and 0 <= ny < grid.shape[1] and grid[nx, ny] == 1:
            neighbors.append((nx, ny))
    return neighbors


# Step 1: Convert grayscale image to binary grid
def convert_image_to_grid(image_path, threshold_value=127):
    gray_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    if gray_img is None:
        print("Error: Image not loaded. Please check the file path.")
        return None

    _, binary_img = cv2.threshold(gray_img, threshold_value, 255, cv2.THRESH_BINARY)
    grid = (binary_img == 255).astype(int)  # White pixels -> 1, Black pixels -> 0
    return grid

def visualize_grid_with_coordinates(grid, skip_factor=5):
    """
    Visualizes the binary grid and overlays it with coordinates of navigable points.

    Parameters:
        grid (numpy.ndarray): Binary grid representing the image (1 for navigable, 0 for obstacles).
        skip_factor (int): The interval at which to skip points for a less dense plot.
    """
    plt.figure(figsize=(10, 8))
    plt.imshow(grid, cmap='gray', origin='upper')

    # Overlay the coordinates on navigable points
    for y in range(0, grid.shape[0], skip_factor):  # Step by skip_factor in rows
        for x in range(0, grid.shape[1], skip_factor):  # Step by skip_factor in columns
            if grid[y, x] == 1:  # Check if the point is navigable
                plt.text(x, y, f"({x},{y})", fontsize=6, color='red', ha='center', va='center')

    plt.title("Navigable Points with Reduced Coordinates")
    plt.xlabel("X")
    plt.ylabel("Y")
    plt.grid(color='white', linestyle='--', linewidth=0.5)
    plt.show()



def selectStartCordinate():
  try:
    x = int(input("Enter the x-coordinate of the endpoint: "))
    y = int(input("Enter the y-coordinate of the endpoint: "))

    return (y, x)
  except ValueError:
    print("Invalid input. Please enter integer values after seeing the coordinates.")
    return (0, 0)

def selectStartCordinate(grid):
  try:
    x = int(input("Enter the x-coordinate of the startpoint: "))
    y = int(input("Enter the y-coordinate of the startpoint: "))

    return (y, x)
  except ValueError:
    print("Invalid input. Please enter integer values after seeing the coordinates.")
    return (0, 0)


def selectEndCordinate(grid):
  try:
    x = int(input("Enter the x-coordinate of the endpoint: "))
    y = int(input("Enter the y-coordinate of the endpoint: "))

    return (y, x)
  except ValueError:
    print("Invalid input. Please enter integer values after seeing the coordinates.")
    return (grid.shape[0] - 1, grid.shape[1] - 1)





# Function to scale the path
def scale_path(path, room_width, room_height, max_x, max_y):
    """
    Scales the given path to fit within the room dimensions.

    Parameters:
        path (list of tuples): List of (x, y) coordinates.
        room_width (float): Room width in meters.
        room_height (float): Room height in meters.
        max_x (int): Maximum x-coordinate in the original grid.
        max_y (int): Maximum y-coordinate in the original grid.

    Returns:
        list of tuples: Scaled (x, y) coordinates.
    """
    scale_x = room_width / max_x
    scale_y = room_height / max_y

    scaled_path = [(x * scale_x, y * scale_y) for x, y in path]
    return scaled_path


# Function to downsample the path
def downsample_path(path, factor):
    return path[::factor]

def show_image(self, image):
    cv2.imshow("Loaded Image", image)
    cv2.waitKey(0)  # Wait for a key press
    cv2.destroyAllWindows()

def plot_path_on_image(image_path, path_coordinates):
    """
    Overlays the path coordinates on the given image and displays it.

    Parameters:
        image_path (str): Path to the image.
        path_coordinates (list of tuple): List of (x, y) coordinates of the path.
    """
    # Load the image
    image = cv2.imread(image_path, cv2.IMREAD_COLOR)
    if image is None:
        print(f"Error: Unable to read the image from {image_path}. Check the path.")
        return

    # Convert the image from BGR to RGB for matplotlib
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Extract x and y coordinates from the path
    x_coords = [coord[0] for coord in path_coordinates]
    y_coords = [coord[1] for coord in path_coordinates]



    # Plot the image and the path
    plt.figure(figsize=(10, 8))
    plt.imshow(image)
    plt.plot(y_coords, x_coords, color='red', marker='o', markersize=2, linewidth=1, label="Path")

    #for coord in path_coordinates:
    #    plt.text(coord[1], coord[0], f"({coord[1]}, {coord[0]})", fontsize=6, color="blue")

    plt.title("Path Overlay on Image")
    plt.axis("on")  # Turn on axes for reference
    plt.legend()
    plt.show()


# Generate your path (or load it from external calculations)
def generate_path():

    # Load the model with custom layers
    model = load_model('/home/thandava/turtlebotsid/src/robot_control/resource/RouteGenerator2.h5', custom_objects={'Conv2DTranspose': custom_conv2d_transpose})

    image_path = '/home/thandava/turtlebotsid/src/robot_control/resource/map27.jpeg'  # Replace with your image path
    input_image_path = predict_and_save_single_image(image_path, model)
    print(f"The preprocessed mask is saved at: {input_image_path}")

    # Load the image
    if os.path.exists(input_image_path):
        input_image = cv2.imread(input_image_path)
        print(f"Image loaded successfully: {input_image_path}")
    else:
        print(f"Image not found: {input_image_path}")
        input_image = None

    # Process the image (example: display)
    if input_image is not None:
        print(f"Image found: {input_image_path}")
        #input_image.show_image(input_image)

    grid = convert_image_to_grid(input_image_path)
    if grid is not None:
        visualize_grid_with_coordinates(grid, skip_factor=5)

    start = selectStartCordinate(grid=grid)  # Starting point (row, col)
    goal = selectEndCordinate(grid=grid)
    print(f"Selected endpoint: {goal}")

    # Step 3: Apply A* to find the shortest path
    path = astar(grid, start, goal)

    if path:
        print("Shortest path found:", path)

    # Step 4: Visualize the extracted path on the original image
    #visualize_path(image_path, path)
    else:
        print("No path found.")

    #Controller call
    scaled_path = scale_path(path, 20, 40, grid.shape[0] - 1, grid.shape[1] - 1)
    downsampled_path = downsample_path(scaled_path, factor=13)  # Keeps every 10th point

    if path:
        print("Shortest sampled path found:", downsampled_path)
        plot_path_on_image(input_image_path, path)

    # Step 4: Visualize the extracted path on the original image
    #visualize_path(image_path, path)
    else:
        print("No sampled path found.")



    return downsampled_path


def main(args=None):
    rclpy.init(args=args)
    turtlebot_controller = TurtleBotController()
    rclpy.spin(turtlebot_controller)
    turtlebot_controller.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()